{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=0gZ-l0npPIca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyg_lib torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
    "# pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "#import scipy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from typing import Optional, Tuple\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "# with open(\"file_info.json\", 'r') as f :\n",
    "#     file_info = json.load(f)\n",
    "    \n",
    "names= ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770, 823)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/media/dxlab/storage/junyeop/dvlog_adj_mat/'\n",
    "#len(os.listdir(PATH + \"image_dep\")), len(os.listdir(PATH + \"image_daily\"))\n",
    "\n",
    "adj_daily = os.listdir(PATH + \"daily/\")\n",
    "adj_depression = os.listdir(PATH + \"depression/\")\n",
    "\n",
    "with open('metadata_features_daily_dvlog.pickle', 'rb') as f :\n",
    "    vlog_daily_metadata_feature = pickle.load(f)\n",
    "with open('metadata_features_diagnosis_dvlog.pickle', 'rb') as f :\n",
    "    vlog_diagnosis_metadata_feature = pickle.load(f)\n",
    "vlog_metadata_feature = vlog_daily_metadata_feature.copy()\n",
    "vlog_metadata_feature.update(vlog_diagnosis_metadata_feature)\n",
    "\n",
    "with open('visual_features_dvlog.pickle', 'rb') as f :\n",
    "    vlog_visual_feature = pickle.load(f)\n",
    "\n",
    "len(vlog_metadata_feature), len(vlog_visual_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_info = dict()\n",
    "\n",
    "have_meta_daily = dict()\n",
    "for i in adj_daily :\n",
    "    if os.path.splitext(i)[0] in list(vlog_metadata_feature.keys()) :\n",
    "        if type(vlog_metadata_feature[os.path.splitext(i)[0]]) == str :\n",
    "            continue\n",
    "        have_meta_daily[os.path.splitext(i)[0]] = vlog_metadata_feature[os.path.splitext(i)[0]]\n",
    "        have_meta_daily[os.path.splitext(i)[0]]['label'] = 0\n",
    "        \n",
    "have_meta_depression = dict()\n",
    "for i in adj_depression :\n",
    "    if os.path.splitext(i)[0] in list(vlog_metadata_feature.keys()) :\n",
    "        if type(vlog_metadata_feature[os.path.splitext(i)[0]]) == str :\n",
    "            continue\n",
    "        have_meta_depression[os.path.splitext(i)[0]] = vlog_metadata_feature[os.path.splitext(i)[0]]\n",
    "        have_meta_depression[os.path.splitext(i)[0]]['label'] = 1\n",
    "        \n",
    "file_info = dict()\n",
    "file_info.update(have_meta_daily)\n",
    "file_info.update(have_meta_depression)\n",
    "len(file_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "file_info = list(file_info.items())\n",
    "random.shuffle(file_info)\n",
    "file_info = dict(file_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_ATTR = 80\n",
    "HIDDEN_DIM = 512\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = torch.eye(len(names), dtype = torch.float32) # node feature matrix all one vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily vlog : 355\n",
      "diagnosis vlog : 415\n"
     ]
    }
   ],
   "source": [
    "labels = list()\n",
    "c0, c1, c2 = 0, 0, 0\n",
    "\n",
    "for x in file_info :\n",
    "    if file_info[x]['label'] == 0:\n",
    "        labels.append(0)\n",
    "        c0 += 1\n",
    "#     elif file_info[x]['label'] == 1 :\n",
    "#         labels.append(1)\n",
    "#         c1 += 1\n",
    "    else :\n",
    "        labels.append(1)\n",
    "        c2 += 1 \n",
    "labels = torch.LongTensor(labels).unsqueeze(dim = 1)\n",
    "print(\"daily vlog : {}\\ndiagnosis vlog : {}\".format(c0, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "770it [00:03, 217.47it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = list()\n",
    "\n",
    "for idx, mat_dir in tqdm(enumerate(file_info)) :\n",
    "\n",
    "    if labels[idx] == 0 :\n",
    "        with open(PATH + \"daily/\" + mat_dir + '.npy', 'rb') as f:\n",
    "            m = np.load(f)\n",
    "#     elif labels[idx] == 1:\n",
    "#         with open(PATH + \"adj_mat/depression/\" + mat_dir + '.npy', 'rb') as f:\n",
    "#             m = np.load(f)\n",
    "    else :\n",
    "        with open(PATH + \"depression/\" + mat_dir + '.npy', 'rb') as f:\n",
    "            m = np.load(f)        \n",
    "    m = nx.adjacency_matrix(nx.from_numpy_array(m))\n",
    "    edge_index, edge_attr = torch_geometric.utils.from_scipy_sparse_matrix(m)\n",
    "    data = Data(edge_index=edge_index, x=feature_matrix, edge_attr = edge_attr, y = labels[idx])\n",
    "    #data = Data(edge_index=edge_index,  edge_attr = edge_attr, y = labels[idx])\n",
    "    dataset.append(data)\n",
    "    \n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [x.y for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.sqrt_dim = np.sqrt(dim)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:\n",
    "        score = torch.bmm(query, key.transpose(1, 2)) / self.sqrt_dim\n",
    "\n",
    "        if mask is not None:\n",
    "            score.masked_fill_(mask.view(score.size()), -float('Inf'))\n",
    "\n",
    "        attn = F.softmax(score, -1)\n",
    "        context = torch.bmm(attn, value)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int = HIDDEN_DIM, num_heads: int = 8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model % num_heads should be zero.\"\n",
    "\n",
    "        self.d_head = int(d_model / num_heads)\n",
    "        self.num_heads = num_heads\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(self.d_head)\n",
    "        self.query_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "        self.key_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "        self.value_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "\n",
    "    def forward(self,\n",
    "                query: Tensor,\n",
    "                key: Tensor,\n",
    "                value: Tensor,\n",
    "                mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:\n",
    "        \n",
    "        batch_size = value.size(0)\n",
    "\n",
    "        query = self.query_proj(query).view(batch_size, -1, self.num_heads, self.d_head)  # BxQ_LENxNxD\n",
    "        key = self.key_proj(key).view(batch_size, -1, self.num_heads, self.d_head)      # BxK_LENxNxD\n",
    "        value = self.value_proj(value).view(batch_size, -1, self.num_heads, self.d_head)  # BxV_LENxNxD\n",
    "\n",
    "        query = query.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)  # BNxQ_LENxD\n",
    "        key = key.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)      # BNxK_LENxD\n",
    "        value = value.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)  # BNxV_LENxD\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.num_heads, 1, 1)  # BxNxQ_LENxK_LEN\n",
    "\n",
    "        context, attn = self.scaled_dot_attn(query, key, value, mask)\n",
    "\n",
    "        context = context.view(self.num_heads, batch_size, -1, self.d_head)\n",
    "        context = context.permute(1, 2, 0, 3).contiguous().view(batch_size, -1, self.num_heads * self.d_head)  # BxTxND\n",
    "\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(Model, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GATConv(NODE_ATTR, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)        \n",
    "        \n",
    "        \n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels//2)\n",
    "        self.lin2 = Linear(hidden_channels//2, hidden_channels//4)\n",
    "        \n",
    "        self.classifier = Linear(hidden_channels//4, len(labels.unique()))\n",
    "        \n",
    "        self.attn = MultiHeadAttention()\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        \n",
    "        # 3. self Attention layer\n",
    "        x = self.attn(x, x, x)[0]\n",
    "\n",
    "        # 5. Apply a final classifier\n",
    "        x = F.dropout(self.lin1(x), p=0.5, training=self.training)\n",
    "        x = F.dropout(self.lin2(x), p=0.5, training=self.training)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_loss = 0.0  \n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.x = data.x.to(device)\n",
    "        data.edge_index = data.edge_index.to(device)\n",
    "        data.batch = data.batch.to(device)\n",
    "        data.y = data.y.to(device)\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        loss = criterion(out, data.y).to(device)  # Compute the loss.\n",
    "        \n",
    "        pred = out.argmax(dim = 1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return correct/len(loader.dataset), total_loss / len(loader)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model(hidden_channels=HIDDEN_DIM).to(device)\n",
    "#model = GCN(hidden_channels=HIDDEN_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, lr, wd):\n",
    "    y_pred = list()\n",
    "    y_test = list()\n",
    "    best_model = torch.load(\"./checkpoint/grid_search/0_binary_depression_unimodal/GAT/best_model_binary_{}_{}.pt\".format(lr, wd))\n",
    "    best_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        \n",
    "        data.x = data.x.to(device)\n",
    "        data.edge_index = data.edge_index.to(device)\n",
    "        data.batch = data.batch.to(device)\n",
    "        data.y = data.y.to(device)\n",
    "        \n",
    "        out = best_model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        \n",
    "        y_pred.extend(pred.tolist())\n",
    "        y_test.extend(data.y.tolist())\n",
    "        \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['daily', 'depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.6765    0.0648    0.1183       355\n",
      "  depression     0.5489    0.9735    0.7020       415\n",
      "\n",
      "    accuracy                         0.5545       770\n",
      "   macro avg     0.6127    0.5191    0.4101       770\n",
      "weighted avg     0.6077    0.5545    0.4329       770\n",
      "\n",
      "0.0001 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7027    0.0732    0.1327       355\n",
      "  depression     0.5512    0.9735    0.7038       415\n",
      "\n",
      "    accuracy                         0.5584       770\n",
      "   macro avg     0.6269    0.5234    0.4182       770\n",
      "weighted avg     0.6210    0.5584    0.4405       770\n",
      "\n",
      "0.0001 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7222    0.0732    0.1330       355\n",
      "  depression     0.5518    0.9759    0.7050       415\n",
      "\n",
      "    accuracy                         0.5597       770\n",
      "   macro avg     0.6370    0.5246    0.4190       770\n",
      "weighted avg     0.6304    0.5597    0.4413       770\n",
      "\n",
      "1e-05 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.6364    0.0394    0.0743       355\n",
      "  depression     0.5441    0.9807    0.6999       415\n",
      "\n",
      "    accuracy                         0.5468       770\n",
      "   macro avg     0.5902    0.5101    0.3871       770\n",
      "weighted avg     0.5866    0.5468    0.4115       770\n",
      "\n",
      "1e-05 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.6522    0.0423    0.0794       355\n",
      "  depression     0.5448    0.9807    0.7005       415\n",
      "\n",
      "    accuracy                         0.5481       770\n",
      "   macro avg     0.5985    0.5115    0.3899       770\n",
      "weighted avg     0.5943    0.5481    0.4141       770\n",
      "\n",
      "1e-05 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.6522    0.0423    0.0794       355\n",
      "  depression     0.5448    0.9807    0.7005       415\n",
      "\n",
      "    accuracy                         0.5481       770\n",
      "   macro avg     0.5985    0.5115    0.3899       770\n",
      "weighted avg     0.5943    0.5481    0.4141       770\n",
      "\n",
      "1e-06 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.0000    0.0000    0.0000       355\n",
      "  depression     0.5390    1.0000    0.7004       415\n",
      "\n",
      "    accuracy                         0.5390       770\n",
      "   macro avg     0.2695    0.5000    0.3502       770\n",
      "weighted avg     0.2905    0.5390    0.3775       770\n",
      "\n",
      "1e-06 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.0000    0.0000    0.0000       355\n",
      "  depression     0.5390    1.0000    0.7004       415\n",
      "\n",
      "    accuracy                         0.5390       770\n",
      "   macro avg     0.2695    0.5000    0.3502       770\n",
      "weighted avg     0.2905    0.5390    0.3775       770\n",
      "\n",
      "1e-06 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.0000    0.0000    0.0000       355\n",
      "  depression     0.5390    1.0000    0.7004       415\n",
      "\n",
      "    accuracy                         0.5390       770\n",
      "   macro avg     0.2695    0.5000    0.3502       770\n",
      "weighted avg     0.2905    0.5390    0.3775       770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "LR_LIST = [1e-4, 1e-5, 1e-6]\n",
    "WEIGHT_DECAY = [1e-3, 1e-4, 1e-5]\n",
    "for lr in LR_LIST :\n",
    "    for wd in WEIGHT_DECAY :\n",
    "        print(lr, wd)\n",
    "        y_test, y_pred = inference(loader, lr, wd)\n",
    "        print(classification_report(y_test, y_pred, target_names = target_names, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jy_gpu_py37",
   "language": "python",
   "name": "jy_gpu_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
