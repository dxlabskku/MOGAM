{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=0gZ-l0npPIca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyg_lib torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
    "# pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/jy_gpu_py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "#import scipy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from typing import Optional, Tuple\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "# with open(\"file_info.json\", 'r') as f :\n",
    "#     file_info = json.load(f)\n",
    "    \n",
    "names= ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1877\n",
      "2568\n",
      "4497\n"
     ]
    }
   ],
   "source": [
    "PATH = '/media/dxlab/storage/junyeop/'\n",
    "#len(os.listdir(PATH + \"image_dep\")), len(os.listdir(PATH + \"image_daily\"))\n",
    "\n",
    "   \n",
    "\n",
    "adj_daily = os.listdir(PATH + \"adj_mat/daily/\")\n",
    "adj_diagnosis = os.listdir(PATH + \"adj_mat/diagnosis/\")\n",
    "adj_before = os.listdir(PATH + \"adj_mat/before/\")\n",
    "\n",
    "\n",
    "# daily vlog feature load\n",
    "with open(\"visual_features_daily_all.pickle\", 'rb') as f :\n",
    "    visual_features_daily = pickle.load(f)\n",
    "with open(\"metadata_features_daily_all.pickle\", 'rb') as f :\n",
    "    meta_daily_features = pickle.load(f)\n",
    "with open(PATH + 'vlog_metadata_daily.pickle', 'rb') as f :\n",
    "    meta_daily = pickle.load(f)\n",
    "with open(PATH + 'vlog_metadata_daily2.pickle', 'rb') as f :\n",
    "    meta_daily2= pickle.load(f)    \n",
    "meta_daily.update(meta_daily2)\n",
    "\n",
    "# depression vlog feature load\n",
    "with open(\"visual_features_diagnosis_all.pickle\", 'rb') as f :\n",
    "    visual_features_diagnosis = pickle.load(f)\n",
    "with open(\"metadata_features_diagnosis_all.pickle\", 'rb') as f :\n",
    "    meta_diagnosis_features = pickle.load(f) \n",
    "\n",
    "# before vlog feature load\n",
    "with open('metadata_features_before.pickle', 'rb') as f :\n",
    "    meta_before_features = pickle.load(f)\n",
    "with open(\"visual_features_before.pickle\", 'rb') as f :\n",
    "    visual_features_before = pickle.load(f)\n",
    "    \n",
    "    \n",
    "meta_features = meta_daily_features.copy()\n",
    "print(len(meta_features))\n",
    "meta_features.update(meta_before_features)\n",
    "print(len(meta_features))\n",
    "meta_features.update(meta_diagnosis_features)\n",
    "print(len(meta_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4470, 1877, 2230, 642)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_info = dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "have_meta_daily = dict()\n",
    "for i in adj_daily :\n",
    "    if os.path.splitext(i)[0] in list(meta_daily.keys()) :\n",
    "        if type(meta_daily[os.path.splitext(i)[0]]) == str :\n",
    "            continue\n",
    "        have_meta_daily[os.path.splitext(i)[0]] = meta_daily[os.path.splitext(i)[0]]\n",
    "        have_meta_daily[os.path.splitext(i)[0]]['label'] = 0\n",
    "        try :\n",
    "            have_meta_daily[os.path.splitext(i)[0]]['visual_feature'] = visual_features_daily[os.path.splitext(i)[0]]\n",
    "        except :\n",
    "            del have_meta_daily[os.path.splitext(i)[0]]   \n",
    "\n",
    "have_meta_diagnosis = dict()\n",
    "for i in adj_diagnosis :\n",
    "    if os.path.splitext(i)[0] in list(meta_diagnosis_features.keys()) :\n",
    "        if type(meta_diagnosis_features[os.path.splitext(i)[0]]) == str :\n",
    "            continue        \n",
    "        have_meta_diagnosis[os.path.splitext(i)[0]] = meta_diagnosis_features[os.path.splitext(i)[0]]\n",
    "        have_meta_diagnosis[os.path.splitext(i)[0]]['label'] = 1\n",
    "        try :\n",
    "            have_meta_diagnosis[os.path.splitext(i)[0]]['visual_feature'] = visual_features_diagnosis[os.path.splitext(i)[0]]\n",
    "        except :\n",
    "            del have_meta_diagnosis[os.path.splitext(i)[0]]            \n",
    "            \n",
    "            \n",
    "have_meta_before = dict()\n",
    "for i in adj_before :\n",
    "    if os.path.splitext(i)[0] in list(meta_before_features.keys()) :\n",
    "        if type(meta_before_features[os.path.splitext(i)[0]]) == str :\n",
    "            continue        \n",
    "        have_meta_before[os.path.splitext(i)[0]] = meta_before_features[os.path.splitext(i)[0]]\n",
    "        have_meta_before[os.path.splitext(i)[0]]['label'] = 2\n",
    "        try :\n",
    "            have_meta_before[os.path.splitext(i)[0]]['visual_feature'] = visual_features_before[os.path.splitext(i)[0]]\n",
    "        except :\n",
    "            del have_meta_before[os.path.splitext(i)[0]]\n",
    "        \n",
    "        \n",
    "file_info = dict()\n",
    "file_info.update(have_meta_daily)\n",
    "file_info.update(have_meta_diagnosis)\n",
    "file_info.update(have_meta_before)\n",
    "        \n",
    "len(file_info), len(have_meta_daily),  len(have_meta_diagnosis), len(have_meta_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "file_info = list(file_info.items())\n",
    "random.shuffle(file_info)\n",
    "file_info = dict(file_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_ATTR = 80\n",
    "HIDDEN_DIM = 1024\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = torch.eye(len(names), dtype = torch.float32) # node feature matrix all one vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily vlog : 1877\n",
      "depression vlog : 1951\n",
      "before vlog : 642\n"
     ]
    }
   ],
   "source": [
    "labels = list()\n",
    "c0, c1, c2 = 0, 0, 0\n",
    "\n",
    "for x in file_info :\n",
    "    if file_info[x]['label'] == 0:\n",
    "        labels.append(0)\n",
    "        c0 += 1\n",
    "    elif file_info[x]['label'] == 1 :\n",
    "        labels.append(1)\n",
    "        c1 += 1\n",
    "    else :\n",
    "        labels.append(2)\n",
    "        c2 += 1 \n",
    "labels = torch.LongTensor(labels).unsqueeze(dim = 1)\n",
    "print(\"daily vlog : {}\\ndepression vlog : {}\\nbefore vlog : {}\".format(c0, c1, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4470it [00:04, 929.72it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = list()\n",
    "\n",
    "for idx, vlog in tqdm(enumerate(file_info)) :\n",
    "\n",
    "    if labels[idx] == 0 :\n",
    "        with open(PATH + \"adj_mat/daily/\" + vlog + '.npy', 'rb') as f:\n",
    "            m = np.load(f)\n",
    "    elif labels[idx] == 1:\n",
    "        with open(PATH + \"adj_mat/diagnosis/\" + vlog + '.npy', 'rb') as f:\n",
    "            m = np.load(f)\n",
    "    else :\n",
    "        with open(PATH + \"adj_mat/before/\" + vlog + '.npy', 'rb') as f:\n",
    "            m = np.load(f)        \n",
    "    m = nx.adjacency_matrix(nx.from_numpy_array(m))\n",
    "    edge_index, edge_attr = torch_geometric.utils.from_scipy_sparse_matrix(m)\n",
    "    data = Data(edge_index=edge_index, x=feature_matrix, edge_attr = edge_attr, y = labels[idx])\n",
    "    \n",
    "    if 'description' in file_info[vlog] :\n",
    "        dataset.append([data, \n",
    "                        file_info[vlog]['visual_feature'], \n",
    "                        meta_features[vlog]['title'], \n",
    "                        meta_features[vlog]['description'], \n",
    "                        meta_features[vlog]['duration']])\n",
    "    \n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily 평균 길이 : 903.3958444326053\n",
      "depressoin 평균 길이 : 396.9897488467453\n",
      " before 평균 길이 : 515.7367601246106\n"
     ]
    }
   ],
   "source": [
    "# check duration average\n",
    "daily_duration, daily_count = 0, 0\n",
    "depression_duration, depression_count = 0, 0\n",
    "before_duration, before_count = 0, 0\n",
    "\n",
    "\n",
    "for x in dataset :\n",
    "    if x[0].y.item() == 0:\n",
    "        daily_count += 1\n",
    "        daily_duration += x[-1].item()\n",
    "    elif x[0].y.item() == 1:\n",
    "        depression_count += 1\n",
    "        depression_duration += x[-1].item()\n",
    "    else :\n",
    "        before_count += 1\n",
    "        before_duration += x[-1].item()\n",
    "print(\"daily 평균 길이 : {}\\ndepressoin 평균 길이 : {}\\n before 평균 길이 : {}\".format(daily_duration/daily_count, depression_duration/depression_count, before_duration/before_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:int(len(dataset)*0.8)]\n",
    "valid_dataset = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n",
    "test_dataset = dataset[int(len(dataset)*0.9):]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [x[0].y for x in train_dataset]\n",
    "y_valid = [x[0].y for x in valid_dataset]\n",
    "y_test = [x[0].y for x in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 192, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.count(0), y_test.count(1), y_test.count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.sqrt_dim = np.sqrt(dim)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:\n",
    "        score = torch.bmm(query, key.transpose(1, 2)) / self.sqrt_dim\n",
    "\n",
    "        if mask is not None:\n",
    "            score.masked_fill_(mask.view(score.size()), -float('Inf'))\n",
    "\n",
    "        attn = F.softmax(score, -1)\n",
    "        context = torch.bmm(attn, value)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int = HIDDEN_DIM, num_heads: int = 8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model % num_heads should be zero.\"\n",
    "\n",
    "        self.d_head = int(d_model / num_heads)\n",
    "        self.num_heads = num_heads\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(self.d_head)\n",
    "        self.query_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "        self.key_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "        self.value_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "\n",
    "    def forward(self,\n",
    "                query: Tensor,\n",
    "                key: Tensor,\n",
    "                value: Tensor,\n",
    "                mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:\n",
    "        \n",
    "        batch_size = value.size(0)\n",
    "\n",
    "        query = self.query_proj(query).view(batch_size, -1, self.num_heads, self.d_head)  # BxQ_LENxNxD\n",
    "        key = self.key_proj(key).view(batch_size, -1, self.num_heads, self.d_head)      # BxK_LENxNxD\n",
    "        value = self.value_proj(value).view(batch_size, -1, self.num_heads, self.d_head)  # BxV_LENxNxD\n",
    "\n",
    "        query = query.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)  # BNxQ_LENxD\n",
    "        key = key.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)      # BNxK_LENxD\n",
    "        value = value.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)  # BNxV_LENxD\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.num_heads, 1, 1)  # BxNxQ_LENxK_LEN\n",
    "\n",
    "        context, attn = self.scaled_dot_attn(query, key, value, mask)\n",
    "\n",
    "        context = context.view(self.num_heads, batch_size, -1, self.d_head)\n",
    "        context = context.permute(1, 2, 0, 3).contiguous().view(batch_size, -1, self.num_heads * self.d_head)  # BxTxND\n",
    "\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GATConv(NODE_ATTR, HIDDEN_DIM)\n",
    "        self.conv2 = GATConv(HIDDEN_DIM, HIDDEN_DIM)\n",
    "        self.conv3 = GATConv(HIDDEN_DIM, HIDDEN_DIM)        \n",
    "        \n",
    "        self.self_attn = MultiHeadAttention()\n",
    "        self.cross_attn = MultiHeadAttention()\n",
    "    \n",
    "        self.visual_linear = nn.Linear(1000, HIDDEN_DIM)   \n",
    "    \n",
    "        # reduce dim\n",
    "        self.title_linear = nn.Linear(768, HIDDEN_DIM//2)\n",
    "        self.description_linear = nn.Linear(768, HIDDEN_DIM//2)\n",
    "        \n",
    "        self.dim_reduce = nn.Linear(2 * HIDDEN_DIM + 1, HIDDEN_DIM)\n",
    "        \n",
    "        self.lin1 = Linear(HIDDEN_DIM, HIDDEN_DIM//2)\n",
    "        self.lin2 = Linear(HIDDEN_DIM//2, HIDDEN_DIM//4)\n",
    "        \n",
    "        self.classifier = Linear(HIDDEN_DIM//4, len(labels.unique()))\n",
    "            \n",
    "    def forward(self, x, edge_index, batch, visual_feature, title, description, duration):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        x = self.self_attn(x, x, x)[0]     \n",
    "        \n",
    "        x_visual = self.visual_linear(visual_feature).squeeze(dim = 1)\n",
    "        \n",
    "        description = self.description_linear(description).squeeze(dim = 1)\n",
    "        title = self.title_linear(title).squeeze(dim = 1)\n",
    "        duration = duration\n",
    "        #print(x_visual.shape, description.shape, title.shape, duration.shape)\n",
    "        x_all = torch.cat([x_visual, description, title, duration], dim = 1)\n",
    "        x_all = self.dim_reduce(x_all)\n",
    "        \n",
    "        x = self.cross_attn(x, x_all, x_all)[0]\n",
    "        \n",
    "        x = F.dropout(self.lin1(x), p=0.5, training=self.training)\n",
    "        x = F.dropout(self.lin2(x), p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model().to(device)\n",
    "\n",
    "MODEL_PATH = './checkpoint/grid_search/3_multiclass_multimodal/GAT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(opt):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total_loss = 0.0\n",
    "    for data, visual_feature, title, description, duration in train_loader: # Iterate in batches over the training dataset.\n",
    "        \n",
    "        data.x = data.x.to(device)\n",
    "        data.edge_index = data.edge_index.to(device)\n",
    "        data.batch = data.batch.to(device)\n",
    "        data.y = data.y.to(device)\n",
    "\n",
    "        visual_feature = visual_feature.to(device)\n",
    "        title = title.to(device)\n",
    "        description = description.to(device)\n",
    "        duration = duration.to(device)\n",
    "\n",
    "#        description = bert_encoder(description).pooler_output\n",
    "#        title = bert_encoder(title).pooler_output   \n",
    "\n",
    "        out = model(x = data.x, \n",
    "                    edge_index = data.edge_index, \n",
    "                    batch = data.batch, \n",
    "                    visual_feature = visual_feature,\n",
    "                    title = title, \n",
    "                    description = description, \n",
    "                    duration = duration)  # Perform a single forward pass.\n",
    "\n",
    "        loss = criterion(out, data.y).to(device)  # Compute the loss.\n",
    "\n",
    "        loss.backward()  # Derive gradients.\n",
    "        opt.step()  # Update parameters based on gradients.\n",
    "        opt.zero_grad()  # Clear gradients.\n",
    "        pred = out.argmax(dim = 1)\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return correct / len(train_loader.dataset), total_loss / len(train_loader)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_loss = 0.0  \n",
    "    for data, visual_feature, title, description, duration in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.x = data.x.to(device)\n",
    "        data.edge_index = data.edge_index.to(device)\n",
    "        data.batch = data.batch.to(device)\n",
    "        data.y = data.y.to(device)\n",
    "        \n",
    "        title = title.to(device)\n",
    "        description = description.to(device)\n",
    "        duration = duration.to(device)\n",
    "        visual_feature = visual_feature.to(device)\n",
    "#         description = bert_encoder(description).pooler_output\n",
    "#         title = bert_encoder(title).pooler_output   \n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch, visual_feature, title, description, duration)\n",
    "        loss = criterion(out, data.y).to(device)  # Compute the loss.\n",
    "        pred = out.argmax(dim = 1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return correct/len(loader.dataset), total_loss / len(loader) # Derive ratio of correct predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|=======================================================================================| 100/100 [04:45<00:00,  2.86s/it, LR=0.0001, WD=0.001, TA=0.708, TL=0.748, VA=0.729, VL=0.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 0.0001, WD : 0.001, Train Acc : 0.7044183445190156, Valid Acc : 0.7427293064876958 , Train Loss : 0.7685129182147128, Valid Loss : 0.667555034160614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|=====================================================================================| 100/100 [04:38<00:00,  2.79s/it, LR=0.0001, WD=0.0001, TA=0.764, TL=0.631, VA=0.734, VL=0.675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 0.0001, WD : 0.0001, Train Acc : 0.7569910514541387, Valid Acc : 0.7829977628635347 , Train Loss : 0.6374494984213795, Valid Loss : 0.596164869410651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|=======================================================================================| 100/100 [05:09<00:00,  3.10s/it, LR=0.0001, WD=1e-5, TA=0.784, TL=0.565, VA=0.747, VL=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 0.0001, WD : 1e-05, Train Acc : 0.7754474272930649, Valid Acc : 0.7740492170022372 , Train Loss : 0.5921159250927823, Valid Loss : 0.5667027320180621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|========================================================================================| 100/100 [05:35<00:00,  3.36s/it, LR=1e-5, WD=0.001, TA=0.708, TL=0.843, VA=0.711, VL=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 1e-05, WD : 0.001, Train Acc : 0.712248322147651, Valid Acc : 0.767337807606264 , Train Loss : 0.8171545464013305, Valid Loss : 0.6503847347838538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|=======================================================================================| 100/100 [05:31<00:00,  3.32s/it, LR=1e-5, WD=0.0001, TA=0.728, TL=0.778, VA=0.747, VL=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 1e-05, WD : 0.0001, Train Acc : 0.714765100671141, Valid Acc : 0.7718120805369127 , Train Loss : 0.8290523612605674, Valid Loss : 0.645790838769504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|==========================================================================================| 100/100 [05:32<00:00,  3.32s/it, LR=1e-5, WD=1e-5, TA=0.732, TL=0.762, VA=0.736, VL=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 1e-05, WD : 1e-05, Train Acc : 0.7178411633109619, Valid Acc : 0.7651006711409396 , Train Loss : 0.8401377347431013, Valid Loss : 0.6543245698724475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|=========================================================================================| 100/100 [05:32<00:00,  3.32s/it, LR=1e-6, WD=0.001, TA=0.655, TL=0.94, VA=0.694, VL=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 1e-06, WD : 0.001, Train Acc : 0.6420581655480985, Valid Acc : 0.7002237136465325 , Train Loss : 0.9567862706524985, Valid Loss : 0.7827978985650199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|=======================================================================================| 100/100 [05:34<00:00,  3.34s/it, LR=1e-6, WD=0.0001, TA=0.661, TL=0.936, VA=0.696, VL=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 1e-06, WD : 0.0001, Train Acc : 0.6442953020134228, Valid Acc : 0.7046979865771812 , Train Loss : 0.9526668576789754, Valid Loss : 0.7790958625929696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 : 100%|==========================================================================================| 100/100 [05:35<00:00,  3.35s/it, LR=1e-6, WD=1e-5, TA=0.66, TL=0.936, VA=0.696, VL=0.807]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, LR : 1e-06, WD : 1e-05, Train Acc : 0.6445749440715883, Valid Acc : 0.7046979865771812 , Train Loss : 0.9524617030152253, Valid Loss : 0.7789109306676048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LR_LIST = [1e-4, 1e-5, 1e-6]\n",
    "WEIGHT_DECAY = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "grid_result = pd.DataFrame(columns=['epoch', 'learning_rate', 'weight_decay', \n",
    "                                    'train_acc', 'valid_acc', \n",
    "                                    'train_loss', 'valid_loss'],\n",
    "                           index= range(len(LR_LIST) * len(WEIGHT_DECAY)))\n",
    "\n",
    "iter_ = 0\n",
    "patience = 0\n",
    "\n",
    "BEST_VALID_ACC = 0\n",
    "BEST_LR = 0\n",
    "BEST_WD = 0\n",
    "prev_valid_loss = 1e+10\n",
    "\n",
    "for lr in LR_LIST :\n",
    "    for wd in WEIGHT_DECAY :\n",
    "        model = Model().to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_loss_list = list()\n",
    "        \n",
    "        valid_loss_list = list()\n",
    "\n",
    "        min_valid_loss = 2e+10\n",
    "\n",
    "        best_epoch = 0\n",
    "        pbar = tqdm(range(EPOCHS), \n",
    "                    ascii = ' =')\n",
    "        \n",
    "        for epoch in pbar :\n",
    "        #for epoch in tqdm(range(EPOCHS)) :\n",
    "            \n",
    "            time.sleep(1)\n",
    "            train_acc, train_loss = train(optimizer)\n",
    "            valid_acc, valid_loss = test(valid_loader)\n",
    "            train_loss_list.append(train_loss)\n",
    "            valid_loss_list.append(valid_loss)\n",
    "            \n",
    "            if valid_loss < min_valid_loss :\n",
    "                best_epoch = epoch\n",
    "                torch.save(model, MODEL_PATH + \"best_model_binary_{}_{}.pt\".format(lr, wd))\n",
    "                torch.save(model.state_dict(), MODEL_PATH + 'best_model_binary_parameters_{}_{}.pt'.format(lr, wd))\n",
    "                min_valid_loss = valid_loss\n",
    "                grid_result.iloc[iter_, :] = [epoch, lr, wd, \n",
    "                                              train_acc, train_loss, \n",
    "                                              valid_acc, valid_loss]\n",
    "                best_ta = train_acc\n",
    "                best_va = valid_acc\n",
    "                best_tl = train_loss\n",
    "                best_vl = valid_loss\n",
    "                \n",
    "                \n",
    "            else :\n",
    "                patience += 1        \n",
    "            pbar.set_description(f'Epoch {epoch+1} ')\n",
    "            pbar.set_postfix({'LR' : lr,\n",
    "                              'WD' : wd,\n",
    "                              'TA' : train_acc,\n",
    "                              'TL' : train_loss, \n",
    "                              'VA' : valid_acc,\n",
    "                              'VL' : valid_loss})        \n",
    "        print(\"Epoch : {}, LR : {}, WD : {}, Train Acc : {}, Valid Acc : {} , Train Loss : {}, Valid Loss : {}\".format(epoch +1, lr, wd, \n",
    "                                                                                                                       best_ta, best_va, \n",
    "                                                                                                                       best_tl, best_vl))\n",
    "        if prev_valid_loss > best_vl :\n",
    "            BEST_VALID_ACC = best_va\n",
    "            BEST_LR = lr\n",
    "            BEST_WD = wd\n",
    "            prev_valid_loss = best_vl\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_LIST = [1e-4, 1e-5, 1e-6]\n",
    "WEIGHT_DECAY = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "def inference(loader, lr, wd):\n",
    "    y_pred = list()\n",
    "    y_test = list()\n",
    "    \n",
    "    best_model = torch.load(MODEL_PATH + \"best_model_binary_{}_{}.pt\".format(lr, wd))\n",
    "    best_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data, visual_feature, title, description, duration in loader: # Iterate in batches over the training/test dataset.\n",
    "        data.x = data.x.to(device)\n",
    "        data.edge_index = data.edge_index.to(device)\n",
    "        data.batch = data.batch.to(device)\n",
    "        data.y = data.y.to(device)\n",
    "        visual_feature = visual_feature.to(device)\n",
    "        title = title.to(device)\n",
    "        description = description.to(device)\n",
    "        duration = duration.to(device)\n",
    "        \n",
    "#        description = bert_encoder(description).pooler_output\n",
    "#        title = bert_encoder(title).pooler_output   \n",
    "        \n",
    "        out = best_model(data.x, data.edge_index, data.batch, visual_feature, title, description, duration)        \n",
    "\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        \n",
    "        y_pred.extend(pred.tolist())\n",
    "        y_test.extend(data.y.tolist())\n",
    "        \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['daily', \"depression\",'before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7458    0.6911    0.7174       191\n",
      "  depression     0.6967    0.7656    0.7295       192\n",
      "      before     0.6780    0.6250    0.6504        64\n",
      "\n",
      "    accuracy                         0.7136       447\n",
      "   macro avg     0.7068    0.6939    0.6991       447\n",
      "weighted avg     0.7150    0.7136    0.7130       447\n",
      "\n",
      "0.0001 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7574    0.8010    0.7786       191\n",
      "  depression     0.7241    0.7656    0.7443       192\n",
      "      before     0.9524    0.6250    0.7547        64\n",
      "\n",
      "    accuracy                         0.7606       447\n",
      "   macro avg     0.8113    0.7306    0.7592       447\n",
      "weighted avg     0.7710    0.7606    0.7605       447\n",
      "\n",
      "0.0001 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.8315    0.7749    0.8022       191\n",
      "  depression     0.7225    0.8542    0.7828       192\n",
      "      before     0.9286    0.6094    0.7358        64\n",
      "\n",
      "    accuracy                         0.7852       447\n",
      "   macro avg     0.8275    0.7461    0.7736       447\n",
      "weighted avg     0.7985    0.7852    0.7844       447\n",
      "\n",
      "1e-05 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7923    0.7592    0.7754       191\n",
      "  depression     0.7295    0.7865    0.7569       192\n",
      "      before     0.7018    0.6250    0.6612        64\n",
      "\n",
      "    accuracy                         0.7517       447\n",
      "   macro avg     0.7412    0.7235    0.7312       447\n",
      "weighted avg     0.7524    0.7517    0.7511       447\n",
      "\n",
      "1e-05 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7737    0.7696    0.7717       191\n",
      "  depression     0.7327    0.7708    0.7513       192\n",
      "      before     0.7273    0.6250    0.6723        64\n",
      "\n",
      "    accuracy                         0.7494       447\n",
      "   macro avg     0.7445    0.7218    0.7317       447\n",
      "weighted avg     0.7494    0.7494    0.7487       447\n",
      "\n",
      "1e-05 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7562    0.7958    0.7755       191\n",
      "  depression     0.7582    0.7188    0.7380       192\n",
      "      before     0.6562    0.6562    0.6562        64\n",
      "\n",
      "    accuracy                         0.7427       447\n",
      "   macro avg     0.7236    0.7236    0.7232       447\n",
      "weighted avg     0.7428    0.7427    0.7423       447\n",
      "\n",
      "1e-06 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7176    0.8115    0.7617       191\n",
      "  depression     0.7081    0.6823    0.6950       192\n",
      "      before     0.5870    0.4219    0.4909        64\n",
      "\n",
      "    accuracy                         0.7002       447\n",
      "   macro avg     0.6709    0.6386    0.6492       447\n",
      "weighted avg     0.6948    0.7002    0.6942       447\n",
      "\n",
      "1e-06 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7196    0.8063    0.7605       191\n",
      "  depression     0.7097    0.6875    0.6984       192\n",
      "      before     0.5957    0.4375    0.5045        64\n",
      "\n",
      "    accuracy                         0.7025       447\n",
      "   macro avg     0.6750    0.6438    0.6545       447\n",
      "weighted avg     0.6976    0.7025    0.6972       447\n",
      "\n",
      "1e-06 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.7170    0.7958    0.7543       191\n",
      "  depression     0.7059    0.6875    0.6966       192\n",
      "      before     0.5833    0.4375    0.5000        64\n",
      "\n",
      "    accuracy                         0.6980       447\n",
      "   macro avg     0.6687    0.6403    0.6503       447\n",
      "weighted avg     0.6931    0.6980    0.6931       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#epoch 500\n",
    "for lr in LR_LIST :\n",
    "    for wd in WEIGHT_DECAY :\n",
    "        print(lr, wd)\n",
    "        y_test, y_pred = inference(test_loader, lr, wd)\n",
    "        print(classification_report(y_test, y_pred, target_names = target_names, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily     0.8315    0.7749    0.8022       191\n",
      "  depression     0.7225    0.8542    0.7828       192\n",
      "      before     0.9286    0.6094    0.7358        64\n",
      "\n",
      "    accuracy                         0.7852       447\n",
      "   macro avg     0.8275    0.7461    0.7736       447\n",
      "weighted avg     0.7985    0.7852    0.7844       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = inference(test_loader, BEST_LR, BEST_WD)\n",
    "print(classification_report(y_test, y_pred, target_names = target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, 1e-05)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BEST_LR, BEST_WD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jy_gpu_py37",
   "language": "python",
   "name": "jy_gpu_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
